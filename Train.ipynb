{"cells":[{"cell_type":"markdown","metadata":{"id":"pstlzKwZ2F1l"},"source":["#Import and Initial Mount Disk\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5333,"status":"ok","timestamp":1652772818404,"user":{"displayName":"Vũ Đức Lâm Nguyễn","userId":"05507541945691209538"},"user_tz":-420},"id":"cflxDTZEGl_F","outputId":"bdf168d9-88f1-4818-f2b9-0ef335207f42"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting tensorflow-addons\n","  Downloading tensorflow_addons-0.16.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[?25l\r\u001b[K     |▎                               | 10 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |▋                               | 20 kB 11.2 MB/s eta 0:00:01\r\u001b[K     |▉                               | 30 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 61 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██                              | 71 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 92 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |███                             | 102 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 112 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 122 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 133 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████                            | 143 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 153 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 163 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████                           | 174 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 184 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 194 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 204 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 215 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 225 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 235 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████                         | 245 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 256 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 266 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 276 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 286 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 296 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 307 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 317 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 327 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 337 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 348 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 358 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 368 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 378 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 389 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 399 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 409 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 419 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 430 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 440 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 450 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 460 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 471 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 481 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 491 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 501 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 512 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 522 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 532 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 542 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 552 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 563 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 573 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 583 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 593 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 604 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 614 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 624 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 634 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 645 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 655 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 665 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 675 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 686 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 696 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 706 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 716 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 727 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 737 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 747 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 757 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 768 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 778 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 788 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 798 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 808 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 819 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 829 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 839 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 849 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 860 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 870 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 880 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 890 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 901 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 911 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 921 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 931 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 942 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 952 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 962 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 972 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 983 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 993 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.0 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.0 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.0 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.0 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.0 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1 MB 5.3 MB/s \n","\u001b[?25hRequirement already satisfied: typeguard\u003e=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n","Installing collected packages: tensorflow-addons\n","Successfully installed tensorflow-addons-0.16.1\n"]}],"source":["# install library\n","!pip install -U tensorflow-addons"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29298,"status":"ok","timestamp":1652772847696,"user":{"displayName":"Vũ Đức Lâm Nguyễn","userId":"05507541945691209538"},"user_tz":-420},"id":"11TpHNGi2BRj","outputId":"96a4ebdc-9962-4886-8f9a-533df968cfeb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["import os\n","# Mount drive\n","from google.colab import drive\n","drive.mount(\"/content/drive\")\n","path = \"/content/drive/My Drive/Colab Notebooks/FaceMaskRecognize\"\n","os.chdir(path)\n","\n","import tensorflow_addons as tfa\n","import tensorflow as tf\n","from tensorflow.keras import models, layers, metrics, optimizers, Model\n","from functools import partial\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import cv2\n","import math\n","import io\n","import pickle\n","import tensorflow_datasets as tfds\n","import random\n","from train.Net import InceptionResNetV1\n","from train.FaceNet import FaceNetModel,call_instance_FaceNet_with_custom, call_instance_FaceNet_without_custom,call_instance_FaceNet_with_last_isDense, convert_train_model_to_embedding\n","from train.Classify import Classify\n","from tool.FormatFunction import FormatFunction\n","from tool.FileFunction import FileFunction\n","from tool.GlobalValue import GlobalValue"]},{"cell_type":"markdown","metadata":{"id":"arWBdNC42LO8"},"source":["# Train"]},{"cell_type":"markdown","metadata":{"id":"cLa5A6udvGwZ"},"source":["## Init value"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":468,"status":"ok","timestamp":1652772848153,"user":{"displayName":"Vũ Đức Lâm Nguyễn","userId":"05507541945691209538"},"user_tz":-420},"id":"-EpkTrUkvL8-"},"outputs":[],"source":["READ_RAW_DATA_THEN_SAVE = False\n","global_value = GlobalValue(image_size=[110,110], batch_size = 512, shuffle_size = 1000, ratio_train = 0.8, ratio_test = 0.1, ratio_valid = 0.1, epochs = 40, small_epochs = 50,\n","                           image_each_class = 15)\n","format_function = FormatFunction(global_value)\n","\n","if READ_RAW_DATA_THEN_SAVE: \n","  label_dict = format_function.get_label_dict(os.path.join(os.getcwd(),\"align_image\"))\n","  path = os.path.join(os.getcwd(),\"src\",\"data\",\"label_dict.pkl\")\n","  with open(path, 'wb') as file:\n","    pickle.dump(label_dict, file)\n","path = os.path.join(os.getcwd(),\"src\",\"data\",\"label_dict.pkl\")\n","with open(path, 'rb') as f:\n","  label_dict = pickle.load(f)\n","\n","file_function = FileFunction()\n"]},{"cell_type":"markdown","metadata":{"id":"j8Rbbjto2TA-"},"source":["## Load data "]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":4569,"status":"ok","timestamp":1652772852720,"user":{"displayName":"Vũ Đức Lâm Nguyễn","userId":"05507541945691209538"},"user_tz":-420},"id":"S4p52uj-InOQ"},"outputs":[],"source":["\n","#Save data path to file to read faster\n","if READ_RAW_DATA_THEN_SAVE:\n","  path_image_align  = file_function.get_data_path_by_dictionary(os.path.join(os.getcwd(),\"align_image\"))\n","  path = os.path.join(os.getcwd(),\"src\",\"data\",\"align_data_path.pkl\")\n","  with open(path, 'wb') as file:\n","      pickle.dump(path_image_align, file)\n","\n","  path_image_mask  = file_function.get_data_path_by_dictionary(os.path.join(os.getcwd(),\"face+mask_image\"))\n","  path = os.path.join(os.getcwd(),\"src\",\"data\",\"face+mask_data_path.pkl\")\n","  with open(path, 'wb') as file:\n","      pickle.dump(path_image_mask, file)\n","\n","# Read data path from file\n","path = os.path.join(os.getcwd(),\"src\",\"data\",\"align_data_path.pkl\")\n","with open(path, 'rb') as f:\n","    path_image_align = pickle.load(f)\n","    path_image_align = file_function.get_data_path_with_limit(path_image_align,global_value.IMAGE_EACH_CLASS)\n","path = os.path.join(os.getcwd(),\"src\",\"data\",\"face+mask_data_path.pkl\")\n","with open(path, 'rb') as f:\n","    path_image_mask = pickle.load(f)\n","    path_image_mask = file_function.get_data_path_with_limit(path_image_mask,global_value.IMAGE_EACH_CLASS)\n","# Combine data path\n","\n","path_image_align.extend(path_image_mask)\n","random.shuffle(path_image_align)\n","label_index =list()\n","for path in path_image_align:\n","  label = path.split(\"/\")[-2]\n","  label = label_dict[label]\n","  label_index.append(label)\n","path_dataset = tf.data.Dataset.from_tensor_slices(path_image_align)\n","label_dataset = tf.data.Dataset.from_tensor_slices(label_index)\n","origin_dataset = tf.data.Dataset.zip((path_dataset, label_dataset))"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1652772852720,"user":{"displayName":"Vũ Đức Lâm Nguyễn","userId":"05507541945691209538"},"user_tz":-420},"id":"hytnbaZDrCua"},"outputs":[],"source":["# for item in origin_dataset.take(10):\n","#   print(item)\n","# for i in range(10):\n","#   print(path_image_align[i], label_index[i])"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":470,"status":"ok","timestamp":1652772853187,"user":{"displayName":"Vũ Đức Lâm Nguyễn","userId":"05507541945691209538"},"user_tz":-420},"id":"zYh7mwb-66Ae"},"outputs":[],"source":["# Repeat data and attach label\n","data_set  = origin_dataset.shuffle(global_value.SHUFFLE_SIZE).repeat(2)\n","\n","\n","# read data from path\n","data_set = data_set.map(format_function.process_image, num_parallel_calls=tf.data.AUTOTUNE)\n","# data_set = data_set.filter(lambda image, label: tf.math.not_equal(tf.size(image), 0))\n","data_set = data_set.map(format_function.augment_data, num_parallel_calls=tf.data.AUTOTUNE)\n","data_set = data_set.shuffle(global_value.SHUFFLE_SIZE)\n","\n","# batch data\n","data_set = data_set.batch(global_value.BATCH_SIZE)\n","\n","# # Set cache and prefetch to improve performance\n","data_set = data_set.prefetch(buffer_size = tf.data.experimental.AUTOTUNE)"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1652772853187,"user":{"displayName":"Vũ Đức Lâm Nguyễn","userId":"05507541945691209538"},"user_tz":-420},"id":"wLM4ytZHoMkA"},"outputs":[],"source":["# for image, label in data_set.take(1):\n","#     plt.imshow(image)\n","#     print(label)\n"]},{"cell_type":"markdown","metadata":{"id":"7Dz4PftxE6XC"},"source":["## Start train"]},{"cell_type":"markdown","metadata":{"id":"lZpKIQAUTDpm"},"source":["# Train version 2\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"QXpeK2-rTN_n"},"outputs":[{"name":"stdout","output_type":"stream","text":["save_model/face_recognize_entropy48\n","--------------------------big epoch 49--------------------------\n","1187/1187 [==============================] - 12325s 10s/step - loss: 0.0644\n","INFO:tensorflow:Assets written to: save_model/face_recognize_entropy49/assets\n","--------------------------big epoch 50--------------------------\n"," 182/1187 [===\u003e..........................] - ETA: 2:33:45 - loss: 0.0792"]}],"source":["# The embedding model\n","input_shape = [global_value.IMAGE_SIZE[0], global_value.IMAGE_SIZE[1], 3]\n","face_net_model = call_instance_FaceNet_with_last_isDense(input_shape, len(label_dict))\n","face_net_model.compile(\n","    optimizer=tf.keras.optimizers.Adam(0.001),\n","    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True)\n","    )\n","#----choose path to save per epoch\n","actual_epochs = 1\n","for i in range(100):\n","  last_save_path = \"save_model/face_recognize_entropy{}\".format(actual_epochs)\n","  if not os.path.exists(last_save_path):\n","    break\n","  actual_epochs += 1\n","\n","# Load save\n","if (actual_epochs != 1):\n","  load_path = \"save_model/face_recognize_entropy{}\".format(actual_epochs-1)\n","  print(load_path)\n","  face_net_model = tf.keras.models.load_model(load_path)\n","\n","\n","\n","# Normal train network\n","for i in range(global_value.EPOCHS):\n","  # Read data path from file\n","  path = os.path.join(os.getcwd(),\"src\",\"data\",\"align_data_path.pkl\")\n","  with open(path, 'rb') as f:\n","      path_image_align = pickle.load(f)\n","      path_image_align = file_function.get_data_path_with_limit(path_image_align,global_value.IMAGE_EACH_CLASS)\n","  path = os.path.join(os.getcwd(),\"src\",\"data\",\"face+mask_data_path.pkl\")\n","  with open(path, 'rb') as f:\n","      path_image_mask = pickle.load(f)\n","      path_image_mask = file_function.get_data_path_with_limit(path_image_mask,global_value.IMAGE_EACH_CLASS)\n","  # Combine data path\n","\n","  path_image_align.extend(path_image_mask)\n","  random.shuffle(path_image_align)\n","  label_index =list()\n","  for path in path_image_align:\n","    label = path.split(\"/\")[-2]\n","    label = label_dict[label]\n","    label_index.append(label)\n","  path_dataset = tf.data.Dataset.from_tensor_slices(path_image_align)\n","  label_dataset = tf.data.Dataset.from_tensor_slices(label_index)\n","  origin_dataset = tf.data.Dataset.zip((path_dataset, label_dataset))\n","  # Repeat data and attach label\n","  data_set  = origin_dataset.shuffle(global_value.SHUFFLE_SIZE).repeat(2)\n","\n","\n","  # read data from path\n","  data_set = data_set.map(format_function.process_image, num_parallel_calls=tf.data.AUTOTUNE)\n","  # data_set = data_set.filter(lambda image, label: tf.math.not_equal(tf.size(image), 0))\n","  data_set = data_set.map(format_function.augment_data, num_parallel_calls=tf.data.AUTOTUNE)\n","  data_set = data_set.shuffle(global_value.SHUFFLE_SIZE)\n","\n","  # batch data\n","  data_set = data_set.batch(global_value.BATCH_SIZE)\n","\n","  # Set cache and prefetch to improve performance\n","  data_set = data_set.prefetch(buffer_size = tf.data.experimental.AUTOTUNE)\n","  print(\"--------------------------big epoch {}--------------------------\".format(actual_epochs))\n","  history = face_net_model.fit(\n","      data_set,\n","      epochs = 1\n","  )\n","  face_net_model.save(\"save_model/face_recognize_entropy{}\".format(actual_epochs))\n","  with open(\"src/loss/face_recognize_entropy.txt\", \"a\") as file_object:\n","    file_object.write(\"\\n\")\n","    file_object.write(\"epoch {}, loss {}, batch {}\". format(actual_epochs, history.history['loss'], global_value.BATCH_SIZE))\n","  actual_epochs += 1"]},{"cell_type":"markdown","metadata":{"id":"77wRLLpnwljL"},"source":["## Plot"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MaizwhSWwm9D"},"outputs":[],"source":["# face_net_model = tf.keras.models.load_model(\"save_model/align_image_origin36\")\n","# classify = Classify(face_net_model, format_function)\n","# database_embedding = classify.embedding_all_data_by_directory(os.path.join(os.getcwd(),\"dataset\",\"lfw\"))\n","# classify.save_embedding_to_file(database_embedding, os.path.join(os.getcwd(),\"encodings\",\"encode_lfw_epoch36.pkl\"))\n","# #Preprocess data\n","# test_dataset = tf.data.Dataset.list_files(\"dataset/lfw/*/*\",shuffle=False)\n","# test_dataset = test_dataset.map(format_function.get_label_as_number, num_parallel_calls=tf.data.AUTOTUNE)\n","# test_dataset = test_dataset.map(format_function.process_image, num_parallel_calls=tf.data.AUTOTUNE)\n","# test_dataset = test_dataset.filter(lambda image, label: tf.math.not_equal(tf.size(image), 0))\n","# test_dataset = test_dataset.batch(20)\n","\n","# # Accuracy\n","# print(classify.evaluate(test_dataset, database_embedding))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lT1WdCieksnL"},"outputs":[],"source":["# # Load network\n","# face_net_model = tf.keras.models.load_model(\"save_model/align_image_origin14\")\n","# #Preprocess data\n","# test_dataset = tf.data.Dataset.list_files(\"10_person/*/*\",shuffle=False)\n","# test_dataset = test_dataset.map(format_function.get_label_as_number, num_parallel_calls=tf.data.AUTOTUNE)\n","# test_dataset = test_dataset.map(format_function.process_image, num_parallel_calls=tf.data.AUTOTUNE)\n","# test_dataset = test_dataset.filter(lambda image, label: tf.math.not_equal(tf.size(image), 0))\n","# test_dataset = test_dataset.batch(20)\n","# # Evaluate the network\n","# results = face_net_model.predict(test_dataset)\n","\n","# # Save test embeddings for visualization in projector\n","# np.savetxt(\"vecs.tsv\", results, delimiter='\\t')\n","\n","# out_m = io.open('meta.tsv', 'w', encoding='utf-8')\n","# for img, labels in tfds.as_numpy(test_dataset):\n","#     [out_m.write(str(x) + \"\\n\") for x in labels]\n","# out_m.close()\n","\n","\n","# try:\n","#   from google.colab import files\n","#   files.download('vecs.tsv')\n","#   files.download('meta.tsv')\n","# except:\n","#   pass"]}],"metadata":{"accelerator":"TPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"Train.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"}},"nbformat":4,"nbformat_minor":0}